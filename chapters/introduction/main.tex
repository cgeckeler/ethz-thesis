\chapter{Introduction}
\label{ch:introduction}

% \dictum[Immanuel Kant]{%
%   Sapere aude! Habe Mut, dich deines eigenen Verstandes zu bedienen! }%
% \vskip 1em

% \begin{otherlanguage}{ngerman}
% Die ältesten Bestimmungen der wahren Grösse der Moleküle hat die kinetische
% Theorie der Gase ermöglicht, während die an Flüssigkeiten beobachteten
% physikalischen Phänomene bis jetzt zur Bestimmung der Molekülgrössen nicht
% gedient haben. \dots
% \end{otherlanguage}

%______________TITLE______________

%Accessible Data Collection from Forests and Agricultural Fields using Aerial Robots through automation and user-centric design

% Democratizing Scalable Environmental Monitoring, Biodiversity Assessment, and Pest Detection using Aerial Robots

% Accessible, Scalable, and Automatable Direct Data Collection using UAVs in Forest environments and agriculutral fields

% 
%_________________________________
% => how to collect data from inaccessible environments => autonomous/user-friendly sensor placement and collection with UAVs

Snailbot Intro:
% Current climate and biodiversity crises \cite{Pereira2024, Weiskopf2024, Pimm2014, Portner2023} underscore the necessity and current lack of comprehensive and scalable environmental and biodiversity monitoring \cite{Gonzalez2023a, McRae2017, Gonzalez2016, Mora2011}. Almost a third of all species assessed by the IUCN RedList are deemed to be threatened, yet less than 8\% of the estimated total number of species have been assessed.
% % Of the 163,040 species assessed by the IUCN, almost a third, over 45,000, are deemed to be threatened. Yet the estimated number of species lies over 2 million, meaning that less than 8\% have been assessed.
% Biodiversity loss has even been linked to reducing global terrestrial carbon storage \cite{Weiskopf2024}, exacerbating and amplifying carbon emissions and climate change, as well as cascading effects across ecosystems \cite{Rosenberg2019, Ceballos2015}, affecting human social and economic prospects \cite{Frank2024, Portner2023}.
% Forests in particular are biodiversity hotspots, home to over half of the world's vertebrate species \cite{Pillay2022} as well as providing essential ecosystem services and climate regulation \cite{Brockerhoff2017}. However, they are challenging to access for data collection, even though this data is essential to understand and protect forest functioning and their impact on biodiversity, climate, and overall ecosystem health. Such data is also vital to evaluate the success of strategies aimed at mitigating climate change and reducing biodiversity loss \cite{Gonzalez2023}, especially within the context of the United Nations (UN) Sustainable Development Goals (SDGs). However, concrete data, especially on biodiversity, ecosystems, and climate are still lacking \cite{Goessmann2023} and costly to collect using conventional, mostly manual methods \cite{Cannon2021, UNEnvironment2019}. 
% Developments in robotic environmental monitoring have shown great promise in both accessing challenging locations as well as scaling data collection through automation \cite{LaVigne2022, Charron2020, Kirchgeorg2024, Hamaza, Aucone2023a, Geckeler2022a}.


\section{The Case for Environmental Data} %2-3 pages
% why is environmental data needed?
% => 
- Context: biodiversity + climate crisis, data collection is necessary to make informed decisions and to evaluate effectiveness of measures
% also in the context of agriculture, more data has resulted in smart farming practices (ie remote senisng), increasing yield, reducing pesticide use, etc

The natural world is in crisis. XX species have declined since XX, with ... Such statistics now seem so commonplace that they seem barely to deserve more than a glanceover, yet it is worth it to have a look at the implications of such numbers. First, these statistics imply that such numbers are based on data, hard incontrovertible data. However, actually most of these statistics /cite are based on projections or outdated publically available datasets. That is not to say that these numbers are not correct or worrying, on the contrary, usually such predictions are more conservative than the reality /cite. The overwhelming abundance of such statistics might also raise the question of whether more data is actually needed, since the trends are clear and the course of action as well (reduced carbon emissions, reduced deforestation, alternative sources of protein, since farming and cattle raising cause XX percent of the world's greenhouse gas emissions as well as one of the primary drivers for deforestation and land use change. Such statistics are not only a call to action, but also a verification that the undertaken steps are leading to the desired outcome. Unfortunately, direct actions taken to address an immediate problem tend to have unintended side-effects, with complex systems and many interdependencies making the results harder to predict.  %% examples?
Natural systems are incredibly complex, and ecosystems have many interdependencies, which predicting positive outcomes challenging. Perhaps a good example of this are carbon credits, where a complex problem has been simplified to a single number, g of carbon, with corresponding min/maxing resulting in monotree farms that do little to promote biodiversity and do not stand the test of time. 
% what is this text?
% need data to check (e.g. carbon sink)

Agriculture stands out as a particularly important field, since it is essential to feed the world's growing  population and provides livelihoods to XX people, yet it also accounts for XX percent of global greenhouse gas emissions, is a major driver for deforestation due to land-use change. One method for reducing the environmental impact of agriculture is through sustainable intensification (SI). The main principles of SI are designed to increase yield and leverage biodiversity to maintain or increase yields while reducing environmentla impact by fostering biodiversity...

Early detection of herbivore pest infestiations in crops can reduce crop losses, limit the amount of applied pesticides, which will also have postiive ripple effects on local biodiveristy such as the insect populations. 
%This will need to rely on novel data sources, such as volatiles, since remote sensing detects too late. 

%RAM paper intro%
% Global agriculture faces unprecedented pressures to feed a growing population, cater to increasingly selective consumer choices, ensure economic viability for the roughly one billion farmers in the world, ensure enough yield with increasingly unpredictable and extreme climate events, and also reduce environmental impact~\cite{McGreevy2022}. Through sustainable intensification (SI), large global change impacts of agriculture can be reduced while increasing yields~\cite{Cassman2020, Pretty2018, Garnett2013}. Many SI strategies leverage productivity gains from increasing biodiversity in farm fields, which can improve land area use and conserve soil through better space-filling. However, the cultivation of such heterogeneous SI fields is more labor-intensive per area than for homogeneous monoculture-based approaches, and not amenable to standard automation strategies for monocultures, which require bare soil and synchronized yields. Smart and adaptive automation is thus critical to upscale SI and provide more food on less land, with fewer negative impacts~\cite{Sparrow2021, Basso2020}.
% A key challenge for SI is the early detection of plant stress for rapid and effective interventions to reduce crop losses, and to optimise the application of pesticides and fertilisers, thereby reducing environmental impact. Precision agriculture thus far has mainly relied on visual imaging technologies such as multi- or hyperspectral cameras to detect plant stress~\cite{Tsouros2019, Toth2016, Singh2020}. A current limitation is that imaging is best suited to identify plant responses to stress at a later stage, i.e., when plants have already undergone substantial damage, because visual damage appears hours or even days after the stress event~(Figure~\ref{fig-1-overview}A)~\cite{mahlein_hyperspectral_2018}. However, plants respond to stress within seconds to hours by producing phytohormones and bioactive chemicals from a variety of pathways~\cite{schuman_layers_2016}. Some of these have sufficiently low vapor pressure to be volatile under standard conditions on Earth, and thus can be perceived at a distance. One of the best-studied phenomena in the field of plant-insect interactions is the production of specific plant volatile blends upon herbivory (10's to 100's of compounds) which indicate the timing and nature of the herbivore as well as the severity of attack~\cite{howe_plant_2008, dicke_evolutionary_2010}. Plant volatiles thus serve as important indicators of plant condition prior to visible or severe damage, and also can indicate the success or failure of some SI strategies. Plant volatiles have been used by insects and other organisms over millions of years to forage on plants and assess plant status, but they are still not exploited for precision agriculture~\cite{turlings_tritrophic_2018}. Volatiles represent an interesting alternative or complement to imaging for early and precise detection of stress and subsequent application of mitigation strategies to reduce yield loss.

Forests are home to over half of the world's vertebrate species /cite ....XXX Yet, they are under threat as wel
% Two ecosystems/environments that are of particular note are forests and agricultural fields. 

% agriculutre:
% - should have different agricultural methods (agrforestry, intercorpping, no tilling, etc) => agriculutre big driver + cause for land use cahnge, greenhouse gases, but also necessary and growing world population

\section{The Case for Direct Data}
% - Problem: Current data collection methods are inadequate, do not enable right type of data collection, cannot access locations, or do not cover temporal or spatial scales needed for proper data analysis. 
% e.g. mostly remote sensing, also for agriculture. also in forests, mostly use satellite data, in person very difficult access 
% different data modalities are needed for full image (ie challenging to assess biodiversity from satellite images
% collected data types are complimentary to remote sensing
% needs to be automated since pure manual sampling is cost prohibitve ( maybe streamlined, reduced human effort
%

In the case of agriculture, precision or smart farming /cite almost exclusively refers to the utilization of additional external data sources in decesion making for pesticited or fertilizer application, for watering, or harvesting times. These data sources usually comprise of remote sensing, either from a UAV flown directly over the field, providing localized, up-to-date, and higher resolution data (multipsectral/thermal), or from commerical satellite feeds which provide coarser information. 
These data sources are all indirect, since they remotely collect data without direct access to the fields inquestion. This makes it easier to collect data at larger scales, but with less information value compared to direct data sources. 
One promising direct data source for agriculture are volatiles, which are ....
Directly collecting volatiles permits early detection of plant stress, more or less directly after the herbivore begins to feed on the plant. This collection is currently mostly done manually, with manual enclosing of plant headspace...  This direct data collection for agriculture is more challenging to collect, especially at larger scales, but is much more informative 
% manual colleciton 
% introduction to volatiles 


Similarly for biodiversity assessment, multiple platforms attempt to provide a silver bullet to the problem of biodiversity monitoring, essentially mainly relying on satellite data, exsisting databases, /cite {gainforest, restor} and sometimes a few localized measurements that are used for extrapolation /cite{that company}. While state of the art algorithms can have impressive performance (e.g. prediciting the habitita of certain fish, inferring the population number of xx). For reliable biodiversity assessments, data still needs to be collected in-situ, whether counting popluations of penguins directly with UAVs /cite, tracking with camera traps, or. ...

eDNA has emerged in recent years as a promising tool for large-scale biodiveristy assessment from single samples. By collecting 
% eDNA intro : collect one sample, aggregated species (water), or manually aggregate through touching many surafecs 
% challenge:difficult to collect

% Environmental data collection also similar, usually just try to extrapolate from a few localized measurements, or use large-scale external (satellite) data to try to combine

% concept of "direct data collection" => ie most current data collections are indirect, passive, and only tangentally measure the features of interest.
% ie remote sensing does not detect the presence of pests, but rather the damage caused by the pests, not direct => need to get close and more directly measure pests
% environmental monitoring proxy measurementns with extrapolations and not in all locations, need to place sensors directly in the region of interest to properly collect data, need to get more into forest and actually maybe interact with forest. 
% biodiveristy monitoring: while large animals (mammals/birds/etc) can be directly seen camera traps, manual visual inspects, etc. other insects/invertebrates/etc harder to detect and accurately count. => EDNA allows direct physical proof of existance, but also requiers physical interaction


% remote data is great, since localized, rich in information, but a) more time/consuming to collect ie not scalable, b) challenging to collect depending on location (forests, agriculutural fields)   => robots?
\section{Robots for Data: Teleoperation and Automation}
% robots can enable direct data collection.
% using aerial robots can also enable access to challenging locations
% gradient of complete manual control (teleoperation) to complete automation
% still currently never full manual control, always some offloaded ie control, PID, , or then waypoint missions maybe abstacle avoidance to full autonomy. 

Robots, in particular aerial robots or UAVs, have provided uniqe

% teleoperation vs automation ( ideally automate everything, however unlikely, so should make available to users
% end-user not necessarly professional drone pilot, but other scientists, so should make accessible. 
% maybe end goal is not full automation, but partial automation with human-in-the-loop, ie all the difficult things are automated so many people can access and do, but the decisions and final say is still with the human pilot.
% => easier legally, pepole also mer accepting, and doesn't require as much complete redundancy as fully automating everything. Also current state of robotics/ML not suited for full auotmation 
% still have increased efficiency and reduced human labor since now one person can supervise multiple robots and tasks are performed faster.

In the case of volatiles for agriculture, while direct data capture is more informative, it is also more timeconsuming and can cover less larger scales than traditoinal remote sensing methods. To still enable use at the scales needed for agriculture, robots are needed.
% aerial robots enabel covering of large areas, and through the option of automation can also image larger scales. 

=> UAVs as a way to access. eg..g sensor deployment, perching, etc.
However, still need specialized hardware, control, complex (ie de-leaves dual person collection)

- Goal: Democratizing scalable data collection methods for environmental monitoring, biodiversity assessment, and agriculture for all locations and all users. (more locations and more users
% 1. ie enable new types of data collection, requiring direct interaction with the environment or objects in the environment
% 2. enable more people to use collect this data through automation and user-friendliness
% - enable new novel locations through the use of UAVs. 

% [maybe this comes after the research questions, as the answer why they are needed]
- Contributions:
1. Collect novel (relevant, vs remote sensing) types of data of environmental factors (eDNA, volatiles) [new data modalities]
2. Initial steps to provide easy-to-use solutions for end-users through automation and user-centric design  (user-friendliness, new data modalities)
3. Enable novel use cases for UAVs, placing and collecting sensors from tree canopies, or placing and collecting sensors from agricultural fields (new locations, new data modalities)
4. Provides access to previously inaccessible locations, and the use of automatable drones permits scaling to larger scales (scalable, new locations)

\section{Dissertation Outline}
In this dissertation we look at the following four research questions within the context of pest detection in agriculture, and biodiversity and environmental monitoring within forests.
% Thesis outline /research questions
Q1. What type of data is necessary to collect for holistic view of environment/biodiv/pest (direct data collection)
Q2. How to democratise direct data collection
Q3: how to enable direct data collection from previously inaccessibel (diffict to access) locations?
Q4: How to scale?
% => (summarized)
Q1: What data is needed for direct data collection? [eDNA, volatiles, direct sensor data]
	%alternative: How to collect direct data for different fields (agriculture, biodiv/env.)
Q2: How to democratize direct data collection? [automation, user-friendliness]
Q3: How to scale direct data collection? [use UAV to access new locations + automate ]
Q4: How to collect direct data from challenging locations? [UAVs for new locations]

Tabel XX shows the contributions to these research questions for each of the papers included in this dissertation. 

\subsection{Pest Detection in Agricultural Fields}
% Part A - looking at XXX
% Paper x,y,z which did whatever...

\subsubsection{Robotic Volatile Sampling for Early Detection of Plant Stress: Precision Agriculture Beyond Visual Remote Sensing \cite{Geckeler2023a}}
%Abstract%
% Global agriculture is challenged to provide food for a human population that is larger than ever before and still increasing. This is accompanied by the need to reduce the large global impacts of agriculture while increasing yields. Early identification of plant stress enables fast intervention to limit crop losses and optimized application of pesticides and fertilizer to reduce environmental impacts. Current image-based approaches identify plant stress responses hours or days after the stress event, usually only after substantial damage has occurred and visual cues become apparent. In contrast, plant volatiles are released seconds to hours after stress events and can quickly indicate both the type and severity of stress. An automatable and nondisruptive sampling method is needed to enable the use of plant volatiles for monitoring plant stress in precision agriculture. In this work, we detail the development of a plant volatile sampler that can be deployed and collected with an uncrewed aerial vehicle (UAV). The effect of sam- pling flow rate, horizontal distance to volatile source, and overhead downwash on collected volatiles is investigated, along with the deployment accuracy and retrieval successes with manual flight. Finally, volatile sampling is validated in outdoor tests. The possibility of robotic collection of plant volatiles is a first and important step toward the use of chemical signals for early stress detection and opens up new avenues for precision agriculture beyond visual remote sensing.

In this work we investigate the process of robotic volatile collection for early pest detection in agriculture. In contrast to remote sensing, which requires visual symptoms and thus damage on the plant to detect pests, volatiles are released seconds to hours after the herbivore event. Volatiles can thus quickly indicate both the type and severity of stress. An automatable and nondisruptive sampling method is needed to enable the use of plant volatiles for monitoring plant stress in precision agriculture. Therefore, we develop a plant volatile sampler that can be deployed and collected with an uncrewed aerial vehicle (UAV). The effect of sampling flow rate, horizontal distance to volatile source, and overhead downwash on collected volatiles is investigated, along with the deployment accuracy and retrieval successes with manual flight. Finally, volatile sampling is validated in outdoor tests. The possibility of robotic collection of plant volatiles is a first and important step toward the use of chemical signals for early stress detection and opens up new avenues for precision agriculture beyond visual remote sensing.
The collection of direct data from agricultural fields, in this case volatiles, allows more informative data collection than from indirect methods, such as remote sensing. In this case, the increased information is temporal, with the derict data permitting earlier detection of pests. However, as with most direct data collection methods, data collection is also more work, requiring the placing and collecting of samplers from the field, which is more challenging than simply flying above it. This work therefore addresses RQ1, enabling the direct data collection of a new data modality, namely volatiles; this work also addresses RQ4, enabling the placing and collecting of sensors in agriculutural fields, which was also not investigated previously. 
%new modality/new locations


\subsubsection{User-Centric Payload Design and Usability Testing for Agricultural Sensor Placement and Retrieval using Off-the-Shelf Micro Aerial Vehicles \cite{Geckeler2024a}}
%Abstract
%—Increased flight time and advanced sensors are making Micro Aerial Vehicles (MAVs) easier to use, facilitating their widespread adoption in fields such as precision agriculture or environmental monitoring. However, current applications are limited mainly to passive visual observation from far above; to enable the next generation of aerial robot applications, MAVs must begin to directly physically interact with objects in the environment, such as placing and collecting sensors. Enabling these applications for a wide spectrum of end-users is only possible if the mechanism is safe and easy to use, without overburdening the user with complex integration, complicated control, or overwhelming and convoluted feedback. To this end we propose a self-sufficient passive payload system to enable both the deployment and retrieval of sensors for agri- culture. This mechanism can be simply mechanically attached to a commercial, off-the-shelf MAV, without requiring further electrical or software integration. The user-centric design and mechanical intelligence of the system facilitates ease of use through simplified control with targeted perceptual feedback. The usability of the system is validated quantitatively and qualitatively in a user study demonstrating sensor deployment and collection. All participants were able to deploy and collect at least four sensors both within 10 minutes in visual line-of- sight and within 12 minutes in beyond visual line-of-sight, after only three minutes of practice. Enabling MAVs to physically interact with their environment will usher in the next stage of MAV utility and applications. Complex tasks, such as sensor deployment and retrieval, can be realized relatively simply, by relying on a mechanically passive system designed with the user in mind, these payloads can enable such applications to be more widely available and inclusive to end-users.

Building on the previous work we address RQ2 and RQ3, enabling more user-friendly collection and retrieval of the sampling mechanism, which also leads to more scalable data collection and lays the initial framework for automation. Many of the user-cues and mechanical intelligence that make the mechanism easier for the user to use, also make it easier to automate. Taking inspiration from commercially available mapping UAVs, which require no specialized training to use, since most of the challenging and monotonous tasks are automated, we also seek to enable new aerial robot applications, such as sensor placement and collection by considering the end-user already during mechansim development. Enabling these applications for a wide spectrum of end-users is only possible if the mechanism is safe and easy to use, without overburdening the user with complex integration, complicated control, or overwhelming and convoluted feedback. To this end we propose a self-sufficient passive payload system to enable both the deployment and retrieval of sensors for agri- culture. This mechanism can be simply mechanically attached to a commercial, off-the-shelf MAV, without requiring further electrical or software integration. The user-centric design and mechanical intelligence of the system facilitates ease of use through simplified control with targeted perceptual feedback. The usability of the system is validated quantitatively and qualitatively in a user study demonstrating sensor deployment and collection. All participants were able to deploy and collect at least four sensors both within 10 minutes in visual line-of- sight and within 12 minutes in beyond visual line-of-sight, after only three minutes of practice. Enabling MAVs to physically interact with their environment will usher in the next stage of MAV utility and applications. Complex tasks, such as sensor deployment and retrieval, can be realized relatively simply, by relying on a mechanically passive system designed with the user in mind, these payloads can enable such applications to be more widely available and inclusive to end-users.

%scalability, automation, user friendliness


\subsection{Environmental Monitoring in Forests}
Forests represent a vital biosphere... home... (biodegrad one)
however, challenging to access, in these chapters look to develop scalable, user-friedly, autoamatable solutions to collect direct data from previously inaccessible locations.

\subsubsection{Bistable Helical Origami Gripper for Sensor Placement on Branches \cite{Geckeler2022a}}
%abstract
%Understanding forest functioning is limited by the scalability of monitoring solutions and difficulty of access. Manual sensor placement can reach most
%locations but lacks scalability. Micro-aerial vehicles (MAVs) allow for scalable sensor delivery, but current solutions are limited to attaching sensors to the trunk or large branches with spines or adhesives. The thinner branches of the outer canopy remain inaccessible, despite being of particular interest due to the
%important physiological processes occurring in the foliage. Herein, a MAV-deployable bistable helically coiling origami gripper is developed. The unfurled
%state allows for transport with a MAV, and when pushed against a branch triggers the second helically coiled state, which permits secure attachment to branches.
%Origami manufacturing keeps the weight of the gripper below 5 g, despite holding up to 280 g, and gripping diameters from 8mm to 38 mm inclined up to
%30°. The holding force, activation force, and resistance to tilt and rotation offsets are experimentally characterized. The deployment and retrieval of the gripper
%and sensor are demonstrated outside, where sensor data are collected from previously inaccessible branches in the outer canopy. Enabling robust sensor
%attachment in the outer canopy marks a step toward scalable environmental monitoring of forest ecosystems.

%now suddenly forests...
%% RQ4, new locations

This work looks at RQ4, enabling direct data collection from the previously inaccessible outer tree canopy in forests. 
오늘이 여기까지


\subsubsection{Biodegradable Origami Gripper Actuated with Gelatin Hydrogel for Aerial Sensor Attachment to Tree Branches \cite{Geckeler2023b}}
%abstract
%Forest canopies are vital ecosystems, but remain understudied due to difficult access. Forests could be monitored with a network of biodegradable sensors that break down into environmentally friendly substances at the end of their life. As a first step in this direction, this paper details the development of a biodegradable origami gripper to attach conventional sensors to branches, deployable with an aerial robot. Through exposure to sufficient moisture the gripper loses contractile force, dropping the sensor to the ground for easier collection. The origami design of the gripper as well as biodegradable materials selection is detailed, allowing for further extensions utilizing biodegradable origami. Both the gripper and the gelatin hydrogel used as an actuating elastic element for generating the grasping force are experimentally characterized, with the gripper demonstrating a maximum holding force of 1 N. Additionally, the degradation of the grip- per until failure in the presence of moisture is also investigated, where the gripper can absorb up to 10 ml of water before falling off a branch. Finally, deployment of the gripper on a tree branch with an aerial robot is demonstrated. Overall, the biodegradable origami gripper represents a first step towards a more scalable and environmentally sustainable approach for ecosystem monitoring.

\subsubsection{WIP: SnailBot: Robotic Environmental Monitoring using Gelatin Hydrogels as a Biodegradable Adhesive}

%Automation
\subsubsection{Learning Occluded Branch Depth Maps in Forest Environments Using RGB-D Images \cite{Geckeler2024}}
%abstract
Covering over a third of all terrestrial land area, forests are crucial environments; as ecosystems, for farming, and for human leisure. However, they are challenging to access for environmental monitoring, for agricultural uses, and for search and rescue applications. To enter, aerial robots need to fly through dense vegetation, where foliage can be pushed aside, but occluded branches pose critical obstacles. Therefore, we propose pixel-wise depth regression of occluded branches using three different U-Net inspired architectures. Given RGB-D input of trees with partially occluded branches, the models estimate depth values of only the wooden parts of the tree. A large photorealistic simulation dataset comprising around 44Kimages ofnine different tree species is gen- erated, on which the models are trained. Extensive evaluation and analysis ofthemodels on this dataset is shown. To improve network generalization to real-world data, different data augmentation and transformation techniques are performed.Theapproaches are then also successfully demonstrated on real-world data of broadleaf trees from Swiss temperate forests and a tropical Masoala Rain- forest. This work showcases the previously unexplored task of frame-by-frame pixel-based occluded branch depth reconstruction to facilitate robot traversal of forest environments.

\subsubsection{WIP: Event Spectroscopy: Event-based Multispectral and Depth Sensing using Structured Light}

\subsection{Biodiversity Assessments in Forests}

\subsubsection{eProbe: Sampling of Environmental DNA within Tree Canopies with Drones \cite{Kirchgeorg2024}}
%abstract
%Environmental DNA (eDNA) analysis is a powerful tool for studying biodiversity in forests and tree canopies. However, collecting representative eDNA samples from these high and complex environments remains challenging. Traditional methods, such as surface swabbing or tree rolling, are labor-intensive and require significant effort to achieve adequate coverage. This study proposes a novel approach for unmanned aerial vehicles (UAVs) to collect eDNA within tree canopies by using a surface swabbing technique. The method involves lowering a probe from a hovering UAV into the canopy and collecting eDNA as it descends and ascends through branches and leaves. To achieve this, a custom- designed robotic system was developed featuring a winch and a probe for eDNA collection. The design of the probe was optimized, and a control logic for the winch was developed to reduce the risk of entanglement while ensuring sufficient interaction force to facilitate transfer ofeDNA onto the probe. The effectiveness of this method was demonstrated during the XPRIZE Rainforest Semi-Finals as 10 eDNA samples were collected from the rainforest canopy, and a total of 152 molecular operational taxonomic units (MOTUs) were identified using eDNA metabarcoding. We further investigate how the number of probe interactions with vegetation, the penetration depth, and the sampling duration influence the DNA concentration and community composition of the samples.

\subsubsection{WIP: Autonomous Surface eDNA Collection from Rainforests: ETH BIODIVX in the XPrize Rainforest Finals}


% Paper Structure (Cyrill): (ie more closely follows the table, then makes all the check boxes at the end
% Chapter 2: manual biodiv/env monitoring in forests
% OG, BOG, SB => Sensor placement + environmental monitoring in new locations (outer-branches forest, near trunk, etc),  all manual

% Chapter 3:
% OBR, ED => towards automation

% Chapter 4: 
% VOL, UR => Sensor placement in agricultural fields + user-friendly (manual)

% Chapter 5:
% EP2, XP => scalable, automated, user-friendly biodv monitoring through eDNO in forest environments

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% OR  (Stefano:)
% Chapter 2: env. monitoring in forests
% OG, BOG, SB => Sensor placement + environmental monitoring in new locations (outer-branches forest, near trunk, etc),  all manual + 
% OBR, ED => towards automation

% Chapter 3: Biodiv. monitoring in forests
% % EP2, XP => scalable, automated, user-friendly biodv monitoring through eDNA in forest environments

% Chapter 4: Pest detection in agriculuture
% VOL, UR => Sensor placement in agricultural fields + user-friendly

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% OR
%================================This is the one========================================
% VOL, UR; OG,BOG,SB; OBR,ED; EP2, XP
% Chapter 2: Pest detection in agriculuture
% VOL, UR => Sensor placement in agricultural fields + user-friendly (don't show automation, etc)

% Chapter 3: env. monitoring in forests
% OG, BOG, SB => Sensor placement + environmental monitoring in new locations (outer-branches forest, near trunk, etc),  all manual + 
% OBR, ED => towards automation

% Chapter 4: Biodiv. monitoring in forests
% % EP2, XP => scalable, automated, user-friendly biodv monitoring through eDNO in forest environments
%========================================================================


% % Table according to #1SM
% \begin{table}
%     \centering 
%     \begin{tabular}{r|ccccccccc}
%             % OG  & BOG & SB & OBR & ED & EP-2 & XP & VOL & UR
%          &  \cite{Geckeler2022a} & \cite{Geckeler2023b} & SB & \cite{Geckeler2024} & ED & \cite{Kirchgeorg2024} & XP & \cite{Geckeler2023a} & \cite{Geckeler2024a}\\
%          \hline \hline
%          New Locations          & X & X & X &   &   & X & X & X &  \\
%          \hline
%          User Friendliness      &   & X &   & X &   & X & X &   & X\\
%          \hline
%          New Data Modalities    &   &   &   &   & X & X & X & X &  \\
%          \hline
%          Automation             &   &   &   & X & X &   & X &   & X\\
%          \hline
%          Scalability            &   &   & X &   & X & X & X & X & X\\
%     \end{tabular}
%     \caption{Caption}
%     \label{tab:my_label}
% \end{table}

% % Table according to #2,CS (switch EP2/XP with VOL/UR)
% \begin{table}
%     \centering 
%     \begin{tabular}{r|ccccccccc}
%             % OG  & BOG & SB & OBR & ED & VOL & UR & EP2 & XP
%          &  \cite{Geckeler2022a} & \cite{Geckeler2023b} & SB & \cite{Geckeler2024} & ED & \cite{Geckeler2023a} & \cite{Geckeler2024a} & \cite{Kirchgeorg2024} & XP \\
%          \hline \hline
%          New Locations          & X & X & X &   &   & X &   & X & X\\
%          \hline
%          User Friendliness      &   & X &   & X &   &   & X & X & X\\
%          \hline
%          New Data Modalities    &   &   &   &   & X & X &   & X & X\\
%          \hline
%          Automation             &   &   &   & X & X &   & X &   & X\\
%          \hline
%          Scalability            &   &   & X &   & X & X & X & X & X\\
%     \end{tabular}
%     \caption{Caption}
%     \label{tab:my_label}
% \end{table}

% Table according to #2,CS (switch EP2/XP with VOL/UR), but with rows switched
\begin{table}
    \centering 
    \begin{tabular}{r|ccccccccc}
            % OG  & BOG & SB & OBR & ED & VOL & UR & EP2 & XP
         &  \cite{Geckeler2022a} & \cite{Geckeler2023b} & SB & \cite{Geckeler2024} & ED & \cite{Geckeler2023a} & \cite{Geckeler2024a} & \cite{Kirchgeorg2024} & XP \\
         \hline \hline
         New Data Modalities    &   &   &   &   & X & X &   & X & X\\
         \hline
         Automation             &   &   &   & X & X &   & X &   & X\\
         \hline
         Scalability            &   &   & X &   & X & X & X & X & X\\
         \hline
         User Friendliness      &   & X &   & X &   &   & X & X & X\\
         \hline
         New Locations          & X & X & X &   &   & X  &   & X & X\\
    \end{tabular}
    \caption{Sorting According to table, increasing points addressed}
    \label{tab:my_label}
\end{table}

% Table according to #3,CS (but with VOL/UR first), and with rows switched
\begin{table}
    \centering 
    \begin{tabular}{r|ccccccccc}
            % VOL & UR & OG  & BOG & SB & OBR & ED & EP2 & XP
         & Pest Det. & Pest Det. & Env. Mon. & Env. Mon. & Env. Mon. & Env. Mon. & Env. Mon. & Biodiv. Assess. & Biodiv. Assess. \\%TODO: make multicolumn for each of the papers
         & \cite{Geckeler2023a} & \cite{Geckeler2024a} &  \cite{Geckeler2022a} & \cite{Geckeler2023b} & SB & \cite{Geckeler2024} & ED & \cite{Kirchgeorg2024} & XP \\
         \hline \hline
         New Data Modalities (Q1)  & X &   &   &   &   &   & X & X & X\\
         \hline
         Automation (Q2)           &   & X &   &   &   & X & X &   & X\\
         \hline
         Scalability (Q3)          & X & X &   &   & X &   & X &  X & X\\
         \hline
         User Friendliness (Q2)    &   & X &   & X &   & X &   &  X & X\\
         \hline
         New Locations (Q4)        & X &   & X & X & X &   &   &  X & X\\
    \end{tabular}
    \caption{Sorting according to themes (Pest detection, env. monitoring, biodiveristy assessment)}
    \label{tab:my_label}
\end{table}

%Q1: What data is needed for direct data collection? [eDNA, volatiles, direct sensor data]
%%alternative: How to collect direct data for different fields (agriculture, biodiv/env.)
%Q2: How to democratize direct data collection? [automation, user-friendliness]
%Q3: How to scale direct data collection? [use UAV to access new locations + automate ]
%Q4: How to collect direct data from challenging locations? [UAVs for new locations]