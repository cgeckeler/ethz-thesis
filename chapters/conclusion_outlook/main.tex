\chapter{Conclusion}
\label{ch:conclusion}

\section{Conclusion}

%did a bunch of cool stuff, major contributions

Direct data presents a valuable opportunity to collect informative, high spatial and temporal resolution data relevant for environmental monitoring and biodiversity assessments in forests, and pest detection in agriculture. To unlock the full potential of direct data, the data collection should be scalable, accessible from challenging locations, and it must be accessible for the end-user.

In this dissertation we provide contributions which enable collection of direct data from new locations, scaling of direct data collection through robotic collection, robotic collection of novel direct data modalities, and ensuring that the solutions are utilized by the end user through user-centric design and automation.

% Nature in crisis, direct data essential to measure quantify and check the effectiveness of solutions.
% to unlock the full potential of direct data, need to make it accessible to end users, in different locations, and for new data modalities
% The main contributions of our work involve making dirct data more accessible, from different locations, for new data modalities over three main tasks: environmenmtal monitoring in forests, biodiversity monitoring in forests , and pest detection in agrcilucture. 

%% Should tie this in with research questions (ie how each question is addressed)
% Q1: Direct data type? [ eDNA, direct sensor data/spectral(?), volatiles]
% Q2: How to democratize direct data collection? [automation, user-friendliness]
% Q3: How to scale direct data collection? [use UAV to access new locations + automate ]
% Q4: challenging locations? [UAVs for new locations]


For early pest detection in agriculture we demonstrate the collection of plant volatiles using pumps deployed and collected with a UAV. This collection of plant volatiles enable direct data collection with this new data modality (RQ1), agricultural fields present a newly accessible location for sensor placement (RQ4), and the deployment and collection via a UAV enhances scalability (RQ3). In a follow-up work we demonstrate a user-centric payload design for sensor placement and collection which allows users to place and collect multiple sensors within minutes using a commercial off-the-shelf UAV, with only simple mechanical integration necessary, demonstrating the importance of user-centric design to enable complex tasks without overwhelming the end-user (RQ2). 

% VOL & UR |& OG  & BOG & SB & OBR & ED &| EP2 & XP
% for pest detection in agriculuture we demonstrate the collection of plant volatiels using pumps which can be collected and placed using a UAV, enabling scalable early pest detection with data modaoilites. 
% In addition ,we demonstrate a user-centric design for the payload, which enables eaiser collection 

% Env. monitoring forests
Our contributions to direct data collection in forests include  sensor deployment to the previously inaccessible, but scientifically interesting thin branches of the outer-canopy (RQ4) using a lightweight helically coiling origami gripper deployed with a UAV. We also demonstrate a biodegradable variant which reduces the ecological footprint of manufacturing the gripper through exclusively using non-fossil based, biodegradable components, which also enhances usability since the gripper must no longer be collected, but will fall from the branch after rainfall thanks to the gelatin hydrogel used as an elastic to facilitate coiling (RQ2).
The same gelatin-hydrogel can also be used as a bidogredable adhesive for adhesion to different substrates for environmental monitoring tasks. We demonstrate that 0.1g of this adhesive can sustain 20N, the adhesive can adhere to different surfaces of different roughnesses, and finally showcase the versatility through three different monitoring tasks, namely placing sensors with a UAV, a perching UAV, and a climbing robot. These three robotic environmental monitoring applications represent access to different parts of the forest, perching UAVs for access to the emergent layer, a climbing robot for access to the canopy, and sensor placement on the trunk for data collection in the understory. This enables access to different parts of the forest (RQ4), and scalability through the use of robotic monitoring (RQ3).


% a major benefit of robotic technologies is the ability to auotamte fully or in part, which can reduce the necessary time, effort, and costs and thus contribuet to the scalability of these technologies
While these applications so far have all been manually operated, to further enhance usability and enable more end-users access to these technologies, it is essential to automate the workflow, either partially or fully. For UAVs flying in forest environments, detecting branches is essential, for navigation to avoid fatal collisions as well as for tasks, such as placing sensors on specific branches. To achieve this, we reconstruct the depth maps of potentially occluded branches using only RGBD input. Despite training only in simulation, the results are promising even on out-of-distribution real-world data, the first step towards automation and increased user-friendliness of the technologies (RQ2,3). Additionally, we demonstrate the use of event-based structured light for enhanced depth perception as well as multi-spectral sensing. This enables multispectral data collection with reduced dependence on ambient light, marking a step towards collecting close-up multispectral data from within tree canopies (RQ1). The utility of the depth and multispectral data is showcased on the downstream task of material differentiation, identifying leaves and branches. The event-camera enables a high refresh rate, making this process well-suited for navigation of UAVs flying through a forest (RQ2,3).

For biodiversity monitoring in forests, we look towards surface-based eDNA as a data modality which provides a cumulative snapshot of biodiversity while being scalable to collect (RQ1). For this we demonstrate both manual operation of the UAV for collection of eDNA from forests in the XPrize Rainforest Semifinals in Singapore, facilitated with an easy-to-use interface \cite{eprobe},  as well as partially and fully autonomous collection in the Amazon Rainforest in Brazil as part of the XPrize Rainforest Finals \cite{}. Autonomous collection is enabled through a processing pipeline which first involves mapping the area using RGB images, rapid processing of the data in the field, then using the resulting heightmap to place sampling points such that the probe maximizes vegetation contact, while maintaining safety for the drone by not going too close to the tree canopy, but close enough to collect data. The solution made even easier to use with easy hardware integration, requiring only a single USB-C connection to the UAV, which then also allows full control using a widget appearing and the standard controller. The fully autonomous surface eDNA collection represents the future of direct data collection: collection of novel data modalities such as eDNA (RQ1), scalability and user-friendliness through automation (RQ2,3), with easy integration and enabling covering of 100 ha of rainforest in only 24 hours, and finally access to very challenging locations, the canopy of a tropical rainforest (RQ4).

These diverse works show that there are many different ways to collect direct data, using different data modalities, including  temperature data from sensors, plant volatiles from agricultural fields, to eDNA from tree canopies. However, all of these have in common that they require interaction with the environment or objects in the environment. To truly unlock the full potential of direct data,  it is necessary to collect different direct data from  different locations at scale, and  especially make the solution usable for the end-users. 
This can be done either through user-friendly hardware design which considers the needs and limitations of the end-users during the design process (UR), easy-to-use interfaces (EP, XP), or through increased automation (OBR, ED, XP). 

Our work takes the first strides in this direction, enabling direct data collection from more locations, using new data modalities, ensuring the solutions are scalable and usable for the end-user through user-friendly design and automation.


\section{Limitations and Outlook} % OK: future research directions

Data collection per area with direct methods is naturally more time and cost intensive than indirect methods, which limits the coverable area with the same effort. 
However, covering with direct methods the same area as indirect methods is most likely not needed, and will also result in data processing bottlenecks due to the  high information density. Rather, the high spatial resolution, in-depth, and localized direct data collection methods compliment the indirect methods with large spatial coverage. Ideally in the future these two data streams would be fused, with a few localized direct measurements which are then extrapolated using large-scale indirect methods with high spatial coverage to provide detailed, information rich, localized data biodiversity and environmental data at scale.
% and direct data which is then extrapolated to scale using indirect methods with high spatial coverage.

%especially for flying robots.
Safety is an important consideration during direct data collection. Since direct data collection is directly in contact with or in close proximity to the environment or objects therein, it is inherently more dangerous than indirect methods which can keep a safe distance. Despite a focus on safety, and works considering enhanced usability through automation, also reducing risk, direct data collection will retain a higher risk. This risk, both to the environment and data capturing robot, should be assessed and minimized on a case-by-case basis.

% should have some concnluding thing about data...

%Automation vs teleoperation
%probably full atuomation not needed, look towards direct data as an inspiration (probably incorporate above text also here)

While automation can be seen as a gradient with increasing automation resulting in less user-effort and higher ease of use, full automation is rarely required. Human input is essential for high-level decision making, such as where to fly and what data to capture, and is a manageable workload. Looking at indirect methods, for instance UAV mapping, complex large scale projects are easy to complete, requiring simply supervision of the process. Especially once direct data are collected, where robots interact with the environment or objects in the environment, the human in the loop becomes even more essential, for safety and legal reasons as much as for which samples to collect. Low-level control other components within the data collection pipeline can and should still be automated, which frees the user for more important high-level decisions.

% Full automation is not required to facilitate use, indirect data collection, such as RGB mapping using UAVs can be a good examlpe of solutions which are easy to use, without requiring complex robotics knowledge. 

% In practice, full automation is rarely required, since human input is essential, especially for high level reasoning such as where and which sample to take.
% The teleoperating user can still be augmented through a user-friendly system with automated low level control and less important components in the pipeline, leaving the user to make high level decisions, such as where to sample or what data to collect, with most of the actual collection then automated.

% limitations??
While user-friendliness and automation is vital for end-user experience, the works for automation UAV navigation in forests remain in the testing phase and are not validated on actual UAVs. Similarly, most of the environmental data collection methods [OG,BOG,SB] (excepting plant volatiles and eDNA) remain a research proof-of-concept for data collection, and were not actively used in the field.

An important aspect of end-user adoption not actively covered in this thesis is the human component. While 

%central component of all robotics, humans should want to have/use robots, but in a lot of cases, humans are adverse to them
% increasing legislation/societal pressures to move away from robots, especiall drones/aerail robots
% Utility and danger to privacy, etc should be balanced.

Robots are made to perceive and interact with their environment, for UAVs, this is beginning to be the case even in more complex environments. By enabling accessible, scalable, direct data collection from challenging locations also for environmental use-cases, for instance early pest detection in agriculture, environmental monitoring in forests, or biodiversity monitoring in forests, we take the initial steps to providing actionable data to address the most pressing issues facing our natural world, and ourselves, today.
